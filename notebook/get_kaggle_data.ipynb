{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planet: Understanding the Amazon from Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download the data directly using the [Kaggle API](https://github.com/Kaggle/kaggle-api). \n",
    "\n",
    "First, install the Kaggle API by uncommenting the following line and executing it, or by executing it in your terminal (depending on your platform you may need to modify this slightly to either add source activate fastai or similar, or prefix pip with a path. Have a look at how conda install is called for your platform (Depending on your environment, you may also need to append \"--user\" to the command)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! {sys.executable} -m pip install kaggle --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you need to upload your credentials from Kaggle on your instance. Login to [Kaggle](www.kaggle.com) and click on your profile picture on the top right corner, then 'My account'. Scroll down until you find a button named 'Create New API Token' and click on it. This will trigger the download of a file named 'kaggle.json'.\n",
    "\n",
    "Upload this file to the directory this notebook is running in, by clicking \"Upload\" on your main Jupyter page, then uncomment and execute the next two commands (or run them in a terminal). For Windows, uncomment the last two commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! mkdir -p ~/.kaggle/\n",
    "# ! mv kaggle.json ~/.kaggle/\n",
    "\n",
    "# For Windows, uncomment these two commands\n",
    "# ! mkdir %userprofile%\\.kaggle\n",
    "# ! move kaggle.json %userprofile%\\.kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're all set to download the data from [planet competition](https://www.kaggle.com/c/planet-understanding-the-amazon-from-space). **You first need to go to its main page and accept its rules**, and run the two cells below (uncomment the shell commands to download and unzip the data). If you get a ```403 forbidden error``` it means you haven't accepted the competition rules yet (you have to go to the competition page, click on *Rules* tab, and then scroll to the bottom to find the accept button)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../data')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('../data')\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! kaggle competitions download -c planet-understanding-the-amazon-from-space -f train-jpg.tar.7z -p {path}  \n",
    "# ! kaggle competitions download -c planet-understanding-the-amazon-from-space -f train_v2.csv -p {path}\n",
    "# ! kaggle competitions download -c planet-understanding-the-amazon-from-space -f test-jpg.tar.7z -p {path}  \n",
    "# ! kaggle competitions download -c planet-understanding-the-amazon-from-space -f test-jpg-additional.tar.7z -p {path} \n",
    "# ! unzip -q -n {path}/train_v2.csv.zip -d {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have trouble downloading the data with the command line tool (it seems there has been an issue getting this particular dataset from the cli), you can navigate to the [competition's data page](https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/data) and manually download the files. You will only need the files: ```train-jpg.tar```, ```train_v2.csv```, ```test-jpg.tar```, and ```test-jpg-additional.tar```. Then upload the files to the directory this notebook is running in by clicking \"Upload\" on your main Jupyter page. You can then uncomment and run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv train-jpg.tar.7z {path}\n",
    "! mv test-jpg.tar.7z {path}\n",
    "! mv test-jpg-additional.tar.7z {path}\n",
    "! mv train_v2.csv.zip {path}\n",
    "! unzip -q -n {path}/train_v2.csv.zip -d {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract the content of this file, we'll need 7zip, so uncomment the following line if you need to install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda install --yes --prefix {sys.prefix} -c haasad eidl7zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can unpack the data (this might take a few minutes to complete)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "! 7za -bd -y -so x {path}/train-jpg.tar.7z | tar xf - -C {path}\n",
    "! 7za -bd -y -so x {path}/test-jpg.tar.7z | tar xf - -C {path}\n",
    "! 7za -bd -y -so x {path}/test-jpg-additional.tar.7z | tar xf - -C {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm {path}/*.tar.7z\n",
    "! rm {path}/*.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having two separate test files is a bit annoying, so I'll combined them from the start to make life easier moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = str(path/'test-jpg-additional/')\n",
    "dest = str(path/'test-jpg')\n",
    "files = os.listdir(source)\n",
    "for f in files:\n",
    "    shutil.move(source+'/'+f, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r {path}/'test-jpg-additional'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# File sizes\n",
      "test-jpg                      958.88MB(61191 files)\n",
      "train_v2.csv                  1.43MB\n",
      "train-jpg                     634.68MB(40479 files)\n",
      "densenet121.pkl               32.64MB\n",
      "resnet50.pkl                  102.86MB\n",
      "resnet152.pkl                 241.92MB\n",
      "test_labels.csv               1.57MB\n",
      "resnet101.pkl                 179.1MB\n",
      "submissions                   33.03MB(14 files)\n",
      "models                        3169.82MB(13 files)\n",
      "addtl_labels.csv              0.79MB\n",
      "densenet169.pkl               57.77MB\n"
     ]
    }
   ],
   "source": [
    "print('# File sizes')\n",
    "p = str(path)\n",
    "for f in os.listdir(p):\n",
    "    if not os.path.isdir(p+'/'+ f):\n",
    "        print (f.ljust(30) + str(round(os.path.getsize(p+'/'+ f) / 1000000, 2)) + 'MB')\n",
    "    else:\n",
    "        sizes = [os.path.getsize(p +'/'+f + '/'+x)/1000000 for x in os.listdir(p+'/'+f)]\n",
    "        print(f.ljust(30) + str(round(sum(sizes), 2)) + 'MB' + '({} files)'.format(len(sizes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:planet-amazon] *",
   "language": "python",
   "name": "conda-env-planet-amazon-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
